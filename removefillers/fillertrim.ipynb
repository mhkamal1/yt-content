{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import whisper_timestamped as whisper\n",
    "import json\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "import os\n",
    "### Set ROOT_DIR\n",
    "ROOT_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Extract audio from video üé•‚Üíüîä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in /Users/kamal/Documents/removefillers/myaudio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "video_path = \"/Users/kamal/Movies/fillerwords_footage/introtake5.TS.mkv\"\n",
    "video = VideoFileClip(video_path)\n",
    "video.audio.write_audiofile(os.path.join(ROOT_DIR, \"myaudio.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load Whisper model and transcribe üéôÔ∏è‚Üíüìù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5107/5107 [00:02<00:00, 2219.28frames/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \" So whenever I'm recording a new video, there are these super-and-like fiddle words that fill the speech. And the reason this occurs is that the brain needs to fill in the process with something. And it also usually occurs when it's the first take of the video and the script really hasn't settled in my head. Now these fiddle words, they are, you know, real annoyance for the audience. You want to figure that you can't unguide them. And for me, as a video producer, I also have to it's a really pain to add the out-of-the-figgered way they begin and really end and then cut out those parts of the video. So for this video, I thought it would be super cool to see whether I could code up a Python project that is able to detect these fiddle words. And also remove them so that I don't have to do that myself.\", 'segments': [{'id': 0, 'seek': 0, 'start': 4.92, 'end': 8.74, 'text': \" So whenever I'm recording a new video, there are these super-and-like\", 'tokens': [50364, 407, 5699, 286, 478, 6613, 257, 777, 960, 11, 456, 366, 613, 1687, 12, 474, 12, 4092, 50796], 'temperature': 0.0, 'avg_logprob': -0.3069173962462182, 'compression_ratio': 1.6337448559670782, 'no_speech_prob': 0.169566348195076, 'confidence': 0.726, 'words': [{'text': 'So', 'start': 4.92, 'end': 5.08, 'confidence': 0.476}, {'text': 'whenever', 'start': 5.08, 'end': 5.34, 'confidence': 0.691}, {'text': \"I'm\", 'start': 5.34, 'end': 5.5, 'confidence': 0.944}, {'text': 'recording', 'start': 5.5, 'end': 5.86, 'confidence': 0.996}, {'text': 'a', 'start': 5.86, 'end': 6.12, 'confidence': 0.964}, {'text': 'new', 'start': 6.12, 'end': 6.28, 'confidence': 0.997}, {'text': '[*]', 'start': 6.28, 'end': 6.42, 'confidence': 0.0}, {'text': 'video,', 'start': 6.42, 'end': 6.88, 'confidence': 0.989}, {'text': '[*]', 'start': 7.16, 'end': 7.6, 'confidence': 0.0}, {'text': 'there', 'start': 7.6, 'end': 7.88, 'confidence': 0.7}, {'text': 'are', 'start': 7.88, 'end': 7.98, 'confidence': 0.967}, {'text': 'these', 'start': 7.98, 'end': 8.18, 'confidence': 0.668}, {'text': 'super-and-like', 'start': 8.18, 'end': 8.74, 'confidence': 0.542}]}, {'id': 1, 'seek': 0, 'start': 8.78, 'end': 13.88, 'text': ' fiddle words that fill the speech. And the reason this occurs is that the brain needs to', 'tokens': [50796, 24553, 2285, 2283, 300, 2836, 264, 6218, 13, 400, 264, 1778, 341, 11843, 307, 300, 264, 3567, 2203, 281, 51058], 'temperature': 0.0, 'avg_logprob': -0.3069173962462182, 'compression_ratio': 1.6337448559670782, 'no_speech_prob': 0.169566348195076, 'confidence': 0.853, 'words': [{'text': 'fiddle', 'start': 8.78, 'end': 9.04, 'confidence': 0.746}, {'text': 'words', 'start': 9.04, 'end': 9.36, 'confidence': 0.918}, {'text': 'that', 'start': 9.36, 'end': 9.74, 'confidence': 0.995}, {'text': 'fill', 'start': 9.74, 'end': 9.94, 'confidence': 0.965}, {'text': 'the', 'start': 9.94, 'end': 10.12, 'confidence': 0.99}, {'text': 'speech.', 'start': 10.12, 'end': 10.58, 'confidence': 0.958}, {'text': 'And', 'start': 11.32, 'end': 11.44, 'confidence': 0.488}, {'text': 'the', 'start': 11.44, 'end': 11.58, 'confidence': 0.991}, {'text': 'reason', 'start': 11.58, 'end': 11.72, 'confidence': 0.975}, {'text': 'this', 'start': 11.72, 'end': 11.9, 'confidence': 0.947}, {'text': 'occurs', 'start': 11.9, 'end': 12.18, 'confidence': 0.994}, {'text': 'is', 'start': 12.18, 'end': 12.52, 'confidence': 0.948}, {'text': 'that', 'start': 12.52, 'end': 12.78, 'confidence': 0.968}, {'text': 'the', 'start': 12.78, 'end': 12.88, 'confidence': 0.93}, {'text': 'brain', 'start': 12.88, 'end': 13.38, 'confidence': 0.786}, {'text': 'needs', 'start': 13.38, 'end': 13.72, 'confidence': 0.639}, {'text': 'to', 'start': 13.72, 'end': 13.88, 'confidence': 0.647}]}, {'id': 2, 'seek': 0, 'start': 14.84, 'end': 19.43, 'text': \" fill in the process with something. And it also usually occurs when it's the first\", 'tokens': [51058, 2836, 294, 264, 1399, 365, 746, 13, 400, 309, 611, 2673, 11843, 562, 309, 311, 264, 700, 51334], 'temperature': 0.0, 'avg_logprob': -0.3069173962462182, 'compression_ratio': 1.6337448559670782, 'no_speech_prob': 0.169566348195076, 'confidence': 0.844, 'words': [{'text': 'fill', 'start': 14.84, 'end': 15.02, 'confidence': 0.993}, {'text': 'in', 'start': 15.02, 'end': 15.22, 'confidence': 0.976}, {'text': 'the', 'start': 15.22, 'end': 15.42, 'confidence': 0.992}, {'text': 'process', 'start': 15.42, 'end': 15.68, 'confidence': 0.186}, {'text': 'with', 'start': 15.68, 'end': 15.9, 'confidence': 0.99}, {'text': 'something.', 'start': 15.9, 'end': 16.34, 'confidence': 0.998}, {'text': '[*]', 'start': 16.34, 'end': 17.26, 'confidence': 0.0}, {'text': 'And', 'start': 17.26, 'end': 17.48, 'confidence': 0.875}, {'text': 'it', 'start': 17.48, 'end': 17.6, 'confidence': 0.963}, {'text': 'also', 'start': 17.6, 'end': 17.84, 'confidence': 0.984}, {'text': 'usually', 'start': 17.84, 'end': 18.18, 'confidence': 0.902}, {'text': 'occurs', 'start': 18.18, 'end': 18.64, 'confidence': 0.996}, {'text': 'when', 'start': 18.64, 'end': 18.98, 'confidence': 0.983}, {'text': \"it's\", 'start': 18.98, 'end': 19.26, 'confidence': 0.859}, {'text': 'the', 'start': 19.26, 'end': 19.3, 'confidence': 0.873}, {'text': 'first', 'start': 19.3, 'end': 19.43, 'confidence': 0.793}]}, {'id': 3, 'seek': 0, 'start': 19.43, 'end': 24.32, 'text': \" take of the video and the script really hasn't settled in my head. Now these\", 'tokens': [51334, 747, 295, 264, 960, 293, 264, 5755, 534, 6132, 380, 14819, 294, 452, 1378, 13, 823, 613, 51575], 'temperature': 0.0, 'avg_logprob': -0.3069173962462182, 'compression_ratio': 1.6337448559670782, 'no_speech_prob': 0.169566348195076, 'confidence': 0.885, 'words': [{'text': 'take', 'start': 19.43, 'end': 19.66, 'confidence': 0.965}, {'text': 'of', 'start': 19.66, 'end': 19.8, 'confidence': 0.883}, {'text': 'the', 'start': 19.8, 'end': 19.96, 'confidence': 0.989}, {'text': 'video', 'start': 19.96, 'end': 20.2, 'confidence': 0.999}, {'text': 'and', 'start': 20.2, 'end': 20.34, 'confidence': 0.853}, {'text': 'the', 'start': 20.34, 'end': 20.5, 'confidence': 0.991}, {'text': 'script', 'start': 20.5, 'end': 20.68, 'confidence': 0.979}, {'text': 'really', 'start': 20.68, 'end': 20.88, 'confidence': 0.682}, {'text': \"hasn't\", 'start': 20.88, 'end': 21.12, 'confidence': 0.718}, {'text': '[*]', 'start': 21.12, 'end': 21.28, 'confidence': 0.0}, {'text': 'settled', 'start': 21.28, 'end': 21.38, 'confidence': 0.995}, {'text': 'in', 'start': 21.38, 'end': 21.56, 'confidence': 0.988}, {'text': 'my', 'start': 21.56, 'end': 21.78, 'confidence': 0.996}, {'text': 'head.', 'start': 21.78, 'end': 22.04, 'confidence': 0.995}, {'text': '[*]', 'start': 22.66, 'end': 23.48, 'confidence': 0.0}, {'text': 'Now', 'start': 23.48, 'end': 24.14, 'confidence': 0.918}, {'text': 'these', 'start': 24.14, 'end': 24.32, 'confidence': 0.646}]}, {'id': 4, 'seek': 0, 'start': 24.32, 'end': 27.89, 'text': ' fiddle words, they are, you know, real annoyance for the audience. You want to', 'tokens': [51575, 24553, 2285, 2283, 11, 436, 366, 11, 291, 458, 11, 957, 8759, 719, 337, 264, 4034, 13, 509, 528, 281, 51754], 'temperature': 0.0, 'avg_logprob': -0.3069173962462182, 'compression_ratio': 1.6337448559670782, 'no_speech_prob': 0.169566348195076, 'confidence': 0.806, 'words': [{'text': 'fiddle', 'start': 24.32, 'end': 24.58, 'confidence': 0.919}, {'text': 'words,', 'start': 24.58, 'end': 24.78, 'confidence': 0.996}, {'text': 'they', 'start': 24.96, 'end': 24.98, 'confidence': 0.695}, {'text': 'are,', 'start': 24.98, 'end': 25.12, 'confidence': 0.977}, {'text': 'you', 'start': 25.14, 'end': 25.16, 'confidence': 0.977}, {'text': 'know,', 'start': 25.16, 'end': 25.4, 'confidence': 0.872}, {'text': 'real', 'start': 25.56, 'end': 25.76, 'confidence': 0.459}, {'text': 'annoyance', 'start': 25.76, 'end': 26.56, 'confidence': 0.649}, {'text': 'for', 'start': 26.56, 'end': 26.9, 'confidence': 0.938}, {'text': 'the', 'start': 26.9, 'end': 27.06, 'confidence': 0.929}, {'text': '[*]', 'start': 27.06, 'end': 27.36, 'confidence': 0.0}, {'text': 'audience.', 'start': 27.36, 'end': 27.5, 'confidence': 0.99}, {'text': 'You', 'start': 27.64, 'end': 27.68, 'confidence': 0.816}, {'text': 'want', 'start': 27.68, 'end': 27.8, 'confidence': 0.679}, {'text': 'to', 'start': 27.8, 'end': 27.89, 'confidence': 0.704}]}, {'id': 5, 'seek': 2780, 'start': 27.89, 'end': 32.1, 'text': \" figure that you can't unguide them. And for me, as a video producer, I also have to\", 'tokens': [50364, 2573, 300, 291, 393, 380, 517, 2794, 482, 552, 13, 400, 337, 385, 11, 382, 257, 960, 12314, 11, 286, 611, 362, 281, 50571], 'temperature': 0.0, 'avg_logprob': -0.38043765017860814, 'compression_ratio': 1.6465863453815262, 'no_speech_prob': 0.009591801092028618, 'confidence': 0.726, 'words': [{'text': 'figure', 'start': 27.89, 'end': 28.1, 'confidence': 0.696}, {'text': 'that', 'start': 28.1, 'end': 28.28, 'confidence': 0.344}, {'text': 'you', 'start': 28.28, 'end': 28.4, 'confidence': 0.889}, {'text': \"can't\", 'start': 28.4, 'end': 28.7, 'confidence': 0.947}, {'text': 'unguide', 'start': 28.7, 'end': 28.94, 'confidence': 0.358}, {'text': 'them.', 'start': 28.94, 'end': 29.2, 'confidence': 0.984}, {'text': '[*]', 'start': 29.2, 'end': 29.76, 'confidence': 0.0}, {'text': 'And', 'start': 29.76, 'end': 29.88, 'confidence': 0.981}, {'text': 'for', 'start': 29.88, 'end': 30.02, 'confidence': 0.967}, {'text': 'me,', 'start': 30.02, 'end': 30.28, 'confidence': 0.997}, {'text': 'as', 'start': 30.42, 'end': 30.5, 'confidence': 0.99}, {'text': 'a', 'start': 30.5, 'end': 30.58, 'confidence': 0.788}, {'text': 'video', 'start': 30.58, 'end': 30.72, 'confidence': 0.985}, {'text': 'producer,', 'start': 30.72, 'end': 31.06, 'confidence': 0.986}, {'text': 'I', 'start': 31.24, 'end': 31.26, 'confidence': 0.805}, {'text': 'also', 'start': 31.26, 'end': 31.5, 'confidence': 0.967}, {'text': 'have', 'start': 31.5, 'end': 31.74, 'confidence': 0.676}, {'text': 'to', 'start': 31.74, 'end': 32.1, 'confidence': 0.507}]}, {'id': 6, 'seek': 2780, 'start': 32.18, 'end': 36.12, 'text': \" it's a really pain to add the out-of-the-figgered way they begin and really end and then\", 'tokens': [50571, 309, 311, 257, 534, 1822, 281, 909, 264, 484, 12, 2670, 12, 3322, 12, 69, 6812, 292, 636, 436, 1841, 293, 534, 917, 293, 550, 50773], 'temperature': 0.0, 'avg_logprob': -0.38043765017860814, 'compression_ratio': 1.6465863453815262, 'no_speech_prob': 0.009591801092028618, 'confidence': 0.538, 'words': [{'text': \"it's\", 'start': 32.18, 'end': 32.36, 'confidence': 0.374}, {'text': 'a', 'start': 32.36, 'end': 32.44, 'confidence': 0.629}, {'text': 'really', 'start': 32.44, 'end': 32.6, 'confidence': 0.983}, {'text': '[*]', 'start': 32.6, 'end': 32.98, 'confidence': 0.0}, {'text': 'pain', 'start': 32.98, 'end': 33.18, 'confidence': 0.531}, {'text': 'to', 'start': 33.18, 'end': 33.38, 'confidence': 0.803}, {'text': 'add', 'start': 33.38, 'end': 33.52, 'confidence': 0.872}, {'text': 'the', 'start': 33.52, 'end': 33.74, 'confidence': 0.368}, {'text': 'out-of-the-figgered', 'start': 33.74, 'end': 34.54, 'confidence': 0.401}, {'text': 'way', 'start': 34.54, 'end': 34.72, 'confidence': 0.928}, {'text': 'they', 'start': 34.72, 'end': 34.84, 'confidence': 0.743}, {'text': 'begin', 'start': 34.84, 'end': 35.14, 'confidence': 0.956}, {'text': 'and', 'start': 35.14, 'end': 35.4, 'confidence': 0.602}, {'text': 'really', 'start': 35.4, 'end': 35.56, 'confidence': 0.4}, {'text': 'end', 'start': 35.56, 'end': 35.84, 'confidence': 0.946}, {'text': 'and', 'start': 35.84, 'end': 36.02, 'confidence': 0.778}, {'text': 'then', 'start': 36.02, 'end': 36.12, 'confidence': 0.497}]}, {'id': 7, 'seek': 2780, 'start': 36.12, 'end': 40.71, 'text': ' cut out those parts of the video. So for this video, I thought it would be super cool to', 'tokens': [50773, 1723, 484, 729, 3166, 295, 264, 960, 13, 407, 337, 341, 960, 11, 286, 1194, 309, 576, 312, 1687, 1627, 281, 51001], 'temperature': 0.0, 'avg_logprob': -0.38043765017860814, 'compression_ratio': 1.6465863453815262, 'no_speech_prob': 0.009591801092028618, 'confidence': 0.924, 'words': [{'text': 'cut', 'start': 36.12, 'end': 36.24, 'confidence': 0.994}, {'text': 'out', 'start': 36.24, 'end': 36.4, 'confidence': 0.989}, {'text': 'those', 'start': 36.4, 'end': 36.6, 'confidence': 0.995}, {'text': 'parts', 'start': 36.6, 'end': 36.84, 'confidence': 0.984}, {'text': 'of', 'start': 36.84, 'end': 36.9, 'confidence': 0.991}, {'text': 'the', 'start': 36.9, 'end': 37.1, 'confidence': 0.995}, {'text': 'video.', 'start': 37.1, 'end': 37.3, 'confidence': 0.998}, {'text': '[*]', 'start': 37.3, 'end': 37.72, 'confidence': 0.0}, {'text': 'So', 'start': 37.72, 'end': 37.9, 'confidence': 0.956}, {'text': 'for', 'start': 37.9, 'end': 38.02, 'confidence': 0.94}, {'text': 'this', 'start': 38.02, 'end': 38.22, 'confidence': 0.998}, {'text': 'video,', 'start': 38.22, 'end': 38.64, 'confidence': 0.996}, {'text': '[*]', 'start': 38.64, 'end': 39.5, 'confidence': 0.0}, {'text': 'I', 'start': 39.5, 'end': 39.66, 'confidence': 0.956}, {'text': 'thought', 'start': 39.66, 'end': 39.88, 'confidence': 0.993}, {'text': 'it', 'start': 39.88, 'end': 39.96, 'confidence': 0.983}, {'text': 'would', 'start': 39.96, 'end': 40.1, 'confidence': 0.98}, {'text': 'be', 'start': 40.1, 'end': 40.18, 'confidence': 0.992}, {'text': 'super', 'start': 40.18, 'end': 40.36, 'confidence': 0.712}, {'text': 'cool', 'start': 40.36, 'end': 40.62, 'confidence': 0.533}, {'text': 'to', 'start': 40.62, 'end': 40.71, 'confidence': 0.76}]}, {'id': 8, 'seek': 2780, 'start': 40.71, 'end': 43.89, 'text': ' see whether I could code up a Python project that is able to detect these', 'tokens': [51001, 536, 1968, 286, 727, 3089, 493, 257, 15329, 1716, 300, 307, 1075, 281, 5531, 613, 51166], 'temperature': 0.0, 'avg_logprob': -0.38043765017860814, 'compression_ratio': 1.6465863453815262, 'no_speech_prob': 0.009591801092028618, 'confidence': 0.877, 'words': [{'text': 'see', 'start': 40.71, 'end': 40.88, 'confidence': 0.996}, {'text': 'whether', 'start': 40.88, 'end': 41.08, 'confidence': 0.981}, {'text': 'I', 'start': 41.08, 'end': 41.34, 'confidence': 0.982}, {'text': 'could', 'start': 41.34, 'end': 41.56, 'confidence': 0.992}, {'text': 'code', 'start': 41.56, 'end': 41.78, 'confidence': 0.481}, {'text': 'up', 'start': 41.78, 'end': 42.0, 'confidence': 0.955}, {'text': 'a', 'start': 42.0, 'end': 42.04, 'confidence': 0.983}, {'text': 'Python', 'start': 42.04, 'end': 42.32, 'confidence': 0.396}, {'text': 'project', 'start': 42.32, 'end': 42.64, 'confidence': 0.99}, {'text': 'that', 'start': 42.64, 'end': 42.82, 'confidence': 0.875}, {'text': 'is', 'start': 42.82, 'end': 42.94, 'confidence': 0.984}, {'text': 'able', 'start': 42.94, 'end': 43.2, 'confidence': 0.997}, {'text': 'to', 'start': 43.2, 'end': 43.42, 'confidence': 0.997}, {'text': 'detect', 'start': 43.42, 'end': 43.74, 'confidence': 0.994}, {'text': 'these', 'start': 43.74, 'end': 43.89, 'confidence': 0.972}]}, {'id': 9, 'seek': 2780, 'start': 43.89, 'end': 47.78, 'text': \" fiddle words. And also remove them so that I don't have to do that myself.\", 'tokens': [51166, 24553, 2285, 2283, 13, 400, 611, 4159, 552, 370, 300, 286, 500, 380, 362, 281, 360, 300, 2059, 13, 51368], 'temperature': 0.0, 'avg_logprob': -0.38043765017860814, 'compression_ratio': 1.6465863453815262, 'no_speech_prob': 0.009591801092028618, 'confidence': 0.868, 'words': [{'text': 'fiddle', 'start': 43.89, 'end': 44.16, 'confidence': 0.511}, {'text': 'words.', 'start': 44.16, 'end': 44.4, 'confidence': 0.992}, {'text': 'And', 'start': 44.9, 'end': 45.04, 'confidence': 0.988}, {'text': 'also', 'start': 45.04, 'end': 45.2, 'confidence': 0.541}, {'text': 'remove', 'start': 45.2, 'end': 45.56, 'confidence': 0.919}, {'text': 'them', 'start': 45.56, 'end': 45.82, 'confidence': 0.991}, {'text': 'so', 'start': 45.82, 'end': 45.98, 'confidence': 0.841}, {'text': 'that', 'start': 45.98, 'end': 46.14, 'confidence': 0.97}, {'text': 'I', 'start': 46.14, 'end': 46.26, 'confidence': 0.976}, {'text': \"don't\", 'start': 46.26, 'end': 46.44, 'confidence': 0.998}, {'text': 'have', 'start': 46.44, 'end': 46.56, 'confidence': 0.993}, {'text': 'to', 'start': 46.56, 'end': 46.7, 'confidence': 0.998}, {'text': 'do', 'start': 46.7, 'end': 46.88, 'confidence': 0.992}, {'text': '[*]', 'start': 46.88, 'end': 47.18, 'confidence': 0.0}, {'text': 'that', 'start': 47.18, 'end': 47.32, 'confidence': 0.994}, {'text': 'myself.', 'start': 47.32, 'end': 47.78, 'confidence': 0.929}]}], 'language': 'en'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "audio = whisper.load_audio(os.path.join(ROOT_DIR, \"myaudio.wav\"))\n",
    "\n",
    "model = whisper.load_model(\"tiny\", device=\"cpu\")\n",
    "\n",
    "result = whisper.transcribe(model, audio, language=\"en\", detect_disfluencies=True)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Get filler words alongwith split times ü§¨~üïû"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filler_words=[]\n",
    "for text in result[\"segments\"]:\n",
    "    for word in text[\"words\"]:\n",
    "        if \"[*]\" in word[\"text\"]:\n",
    "            filler_words.append([word[\"start\"], word[\"end\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6.28, 6.42],\n",
       " [7.16, 7.6],\n",
       " [16.34, 17.26],\n",
       " [21.12, 21.28],\n",
       " [22.66, 23.48],\n",
       " [27.06, 27.36],\n",
       " [29.2, 29.76],\n",
       " [32.6, 32.98],\n",
       " [37.3, 37.72],\n",
       " [38.64, 39.5],\n",
       " [46.88, 47.18]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filler_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_times = []\n",
    "final_end_time = result[\"segments\"][-1][\"end\"]\n",
    "\n",
    "for i in range(len(filler_words)):\n",
    "    if i == 0:\n",
    "        start = 0\n",
    "        end = filler_words[i][0]\n",
    "    else:\n",
    "        start = filler_words[i-1][1]\n",
    "        end = filler_words[i][0]  \n",
    "        filler_words[i]\n",
    "        \n",
    "    split_times.append([start, end])\n",
    "split_times.append([filler_words[-1][1], final_end_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 6.28],\n",
       " [6.42, 7.16],\n",
       " [7.6, 16.34],\n",
       " [17.26, 21.12],\n",
       " [21.28, 22.66],\n",
       " [23.48, 27.06],\n",
       " [27.36, 29.2],\n",
       " [29.76, 32.6],\n",
       " [32.98, 37.3],\n",
       " [37.72, 38.64],\n",
       " [39.5, 46.88],\n",
       " [47.18, 47.78]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Split video into (filler-free) chunks ü§ì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(split_times)):\n",
    "    start_time = split_times[i][0]\n",
    "    end_time = split_times[i][1]\n",
    "    ffmpeg_extract_subclip(video_path, start_time, end_time, targetname=ROOT_DIR+\"/cutvid\"+str(i)+\".mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Merge videos into one final video üòÉ ‚úÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /Users/kamal/Documents/removefillers/final.mp4.\n",
      "MoviePy - Writing audio in finalTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/kamal/Documents/removefillers/final.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/kamal/Documents/removefillers/final.mp4\n"
     ]
    }
   ],
   "source": [
    "clips=[]\n",
    "for i in range(len(split_times)):\n",
    "    clip = ROOT_DIR+\"/cutvid\"+str(i)+\".mp4\"\n",
    "    clips = clips + [VideoFileClip(clip)]\n",
    "\n",
    "final_clip = concatenate_videoclips(clips)\n",
    "final_clip.write_videofile(os.path.join(ROOT_DIR, \"final.mp4\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
